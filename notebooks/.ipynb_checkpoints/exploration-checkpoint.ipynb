{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85517680-cdf1-4ce0-b3e4-aaf15e22a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Detected execution inside 'C:\\Users\\rahul\\Spotify-Listening-Analysis\\notebooks'. Saving files to parent directory...\n",
      "‚úÖ Created: ../src/__init__.py\n",
      "‚úÖ Created: ../src/etl.py\n",
      "‚úÖ Created: ../src/feature_eng.py\n",
      "‚úÖ Created: ../src/predictive_model.py\n",
      "‚úÖ Created: ../src/clustering.py\n",
      "\n",
      "üéâ SUCCESS! All Python files have been created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- 1. DETECT LOCATION & SETUP PATHS ---\n",
    "# If running inside 'notebooks', we save to the parent folder \"../src\"\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    print(f\"üìÇ Detected execution inside '{os.getcwd()}'. Saving files to parent directory...\")\n",
    "    base_dir = \"../src\"\n",
    "else:\n",
    "    print(f\"üìÇ Detected execution in root. Saving files to 'src/' directory...\")\n",
    "    base_dir = \"src\"\n",
    "\n",
    "# Create the directory\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# --- FILE 1: __init__.py ---\n",
    "init_code = \"\"\"\n",
    "from .etl import load_data\n",
    "from .feature_eng import engineer_features\n",
    "from .predictive_model import train_skip_model\n",
    "from .clustering import cluster_listeners\n",
    "\"\"\"\n",
    "with open(os.path.join(base_dir, \"__init__.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(init_code)\n",
    "print(f\"‚úÖ Created: {base_dir}/__init__.py\")\n",
    "\n",
    "# --- FILE 2: etl.py ---\n",
    "etl_code = \"\"\"\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def load_data(raw_data_path):\n",
    "    print(f\"üìÇ ETL Started: Looking for data in {raw_data_path}...\")\n",
    "    files = glob.glob(os.path.join(raw_data_path, \"*.json\"))\n",
    "    \n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"‚ùå No JSON files found in {raw_data_path}. Please move your files there.\")\n",
    "    \n",
    "    data_frames = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            data_frames.append(pd.DataFrame(data))\n",
    "            \n",
    "    df = pd.concat(data_frames, ignore_index=True)\n",
    "    \n",
    "    if 'ts' in df.columns:\n",
    "        df['ts'] = pd.to_datetime(df['ts'])\n",
    "    \n",
    "    df['master_metadata_track_name'] = df['master_metadata_track_name'].fillna('Unknown Track')\n",
    "    df['master_metadata_album_artist_name'] = df['master_metadata_album_artist_name'].fillna('Unknown Artist')\n",
    "    \n",
    "    if 'ms_played' in df.columns and 'skipped' in df.columns:\n",
    "        df = df[(df['ms_played'] > 10000) | (df['skipped'] == True)]\n",
    "        \n",
    "    print(f\"‚úÖ ETL Complete. Processed {len(df)} rows.\")\n",
    "    return df\n",
    "\"\"\"\n",
    "with open(os.path.join(base_dir, \"etl.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(etl_code)\n",
    "print(f\"‚úÖ Created: {base_dir}/etl.py\")\n",
    "\n",
    "# --- FILE 3: feature_eng.py ---\n",
    "feat_code = \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def engineer_features(df):\n",
    "    print(\"‚öôÔ∏è Feature Engineering Started...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['hour'] = df['ts'].dt.hour\n",
    "    df['day_of_week'] = df['ts'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    \n",
    "    if 'skipped' in df.columns:\n",
    "        df['is_skipped'] = df['skipped'].astype(int)\n",
    "    else:\n",
    "        df['is_skipped'] = 0\n",
    "        \n",
    "    if 'reason_start' in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df['reason_start_encoded'] = le.fit_transform(df['reason_start'].astype(str))\n",
    "        \n",
    "    if 'shuffle' in df.columns:\n",
    "        df['shuffle_feature'] = df['shuffle'].astype(int)\n",
    "        \n",
    "    return df\n",
    "\"\"\"\n",
    "with open(os.path.join(base_dir, \"feature_eng.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(feat_code)\n",
    "print(f\"‚úÖ Created: {base_dir}/feature_eng.py\")\n",
    "\n",
    "# --- FILE 4: predictive_model.py ---\n",
    "model_code = \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_skip_model(df):\n",
    "    print(\"ü§ñ Training Predictive Model (Random Forest)...\")\n",
    "    \n",
    "    features = ['ms_played', 'hour', 'day_of_week', 'is_weekend']\n",
    "    if 'reason_start_encoded' in df.columns:\n",
    "        features.append('reason_start_encoded')\n",
    "    if 'shuffle_feature' in df.columns:\n",
    "        features.append('shuffle_feature')\n",
    "        \n",
    "    X = df[features]\n",
    "    y = df['is_skipped']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"üéØ Model Results - AUC Score: {auc_score:.2f}\")\n",
    "    return rf_model, auc_score, features\n",
    "\"\"\"\n",
    "with open(os.path.join(base_dir, \"predictive_model.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(model_code)\n",
    "print(f\"‚úÖ Created: {base_dir}/predictive_model.py\")\n",
    "\n",
    "# --- FILE 5: clustering.py ---\n",
    "cluster_code = \"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cluster_listeners(df):\n",
    "    print(\"‚ú® Running K-Means Clustering on Artists...\")\n",
    "    \n",
    "    artist_stats = df.groupby('master_metadata_album_artist_name').agg({\n",
    "        'ms_played': 'sum',\n",
    "        'is_skipped': 'mean',\n",
    "        'ts': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    artist_stats.columns = ['Artist', 'Total_Ms', 'Skip_Rate', 'Play_Count']\n",
    "    data = artist_stats[artist_stats['Play_Count'] > 20].copy()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(data[['Skip_Rate', 'Play_Count']])\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    data['Cluster'] = kmeans.fit_predict(X)\n",
    "    \n",
    "    print(\"‚úÖ Clustering Complete.\")\n",
    "    return data\n",
    "\"\"\"\n",
    "with open(os.path.join(base_dir, \"clustering.py\"), \"w\", encoding='utf-8') as f:\n",
    "    f.write(cluster_code)\n",
    "print(f\"‚úÖ Created: {base_dir}/clustering.py\")\n",
    "\n",
    "print(\"\\nüéâ SUCCESS! All Python files have been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a8dbf-218e-429d-bc27-9d1846c136f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Add the parent directory to the path so Python finds the 'src' folder\n",
    "# (We go up one level from 'notebooks' to the main project folder)\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# 2. Import the modules you just created\n",
    "from src.etl import load_data\n",
    "from src.feature_eng import engineer_features\n",
    "from src.predictive_model import train_skip_model\n",
    "from src.clustering import cluster_listeners\n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "try:\n",
    "    # A. Load Data\n",
    "    # Points to ../data/raw relative to the notebook\n",
    "    raw_path = os.path.join('..', 'data', 'raw') \n",
    "    df = load_data(raw_path)\n",
    "    \n",
    "    # B. Feature Engineering\n",
    "    df_features = engineer_features(df)\n",
    "    \n",
    "    # C. Run Predictive Model (Resume Validation)\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    rf_model, auc, features = train_skip_model(df_features)\n",
    "    print(f\"‚úÖ RESUME PROOF: Model AUC Score is {auc:.2f}\")\n",
    "    print(\"-----------------------------------\\n\")\n",
    "\n",
    "    # D. Run Clustering (Resume Validation)\n",
    "    clustered_df = cluster_listeners(df_features)\n",
    "    \n",
    "    # --- VISUALIZATION (The \"Improvement\") ---\n",
    "    \n",
    "    # Graph 1: Feature Importance (Why do you skip songs?)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    importances = rf_model.feature_importances_\n",
    "    indices = range(len(importances))\n",
    "    plt.barh(indices, importances, align='center')\n",
    "    plt.yticks(indices, features)\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Why do I skip songs? (Feature Importance)')\n",
    "    plt.show()\n",
    "\n",
    "    # Graph 2: Clusters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=clustered_df, x='Play_Count', y='Skip_Rate', hue='Cluster', palette='viridis', s=100)\n",
    "    plt.title('My Music Taste Clusters')\n",
    "    plt.xlabel('Play Count')\n",
    "    plt.ylabel('Skip Rate')\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n‚ùå ERROR: {e}\")\n",
    "    print(\"Please make sure your .json files are inside the 'data/raw' folder!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Something went wrong: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
